{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt selection and testing\n",
    "\n",
    "This notebook chooses the most appropriate prompt and prompt structure for the OCR correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import config  # Import your config.py file this contains you openai api key\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from llm_comparison_toolkit import RateLimiter, get_response_openai, get_response_anthropic,  create_config_dict_func, use_df_to_call_llm_api, compare_request_configurations\n",
    "from evaluate import load\n",
    "from evaluation_funcs import evaluate_correction_performance, evaluate_correction_performance_folders, get_metric_error_reduction\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dev_transcripts = 'data/dev_data_transcript'\n",
    "\n",
    "#load the dev and test sets for prompt development and selection\n",
    "dev_data_df = pd.read_csv('data/dev_data_raw.csv')\n",
    "test_data_df = pd.read_csv('data/test_data_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different system prompts\n",
    "\n",
    "This explores a range of system prompt to find the one that appears to work the best, we use gpt4 as the baseline model.\n",
    "\n",
    "Although there is no comparison with all models we do test gpt3.5 gpt4, clause haiku and claude opus, in addition we put the prompt in the system message and the prompt after the text becuase this may affect the quality of the result. When the prompt is after the text the response has \"nosm_\" (no system message) appended to the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a modular set of system messages that can be combined in different ways\n",
    "basic_prompt = \"Please recover the text from the corrupted OCR.\"\n",
    "expertise_prompt = \"You are an expert in post-OCR correction of documents.\"\n",
    "recover_prompt = \"Using the context available from the text please recover the most likely original text from the corrupted OCR.\"\n",
    "publication_context_prompt = \"The text is from an english newspaper in the 1800's.\"\n",
    "text_context_prompt = \"The text may be an advert or article and may be missing the beggining or end.\"\n",
    "additional_instructions_prompt = \"Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\n",
    "\n",
    "#combine all the message parts into a variety of system messages, a tuple is used where 0 is the name of the message and 1 is the message itself\n",
    "#N.B. This is not and exhaustive combination as that would be very expensive and likley not yield significantly better results\n",
    "system_messages_list = [\n",
    "('basic_prompt', basic_prompt),\n",
    "('expert_basic_prompt', expertise_prompt + ' '+ basic_prompt),\n",
    "('expert_recover_prompt', expertise_prompt + ' '+ recover_prompt),\n",
    "('expert_recover_publication_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt),\n",
    "('expert_recover_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_publication_text_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt),\n",
    "('expert_recover_instructions_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + additional_instructions_prompt),\n",
    "('full_context_prompt', expertise_prompt + ' '+ recover_prompt + ' ' + publication_context_prompt + ' ' + text_context_prompt+ ' ' + additional_instructions_prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function is used to make the creation of the config dictionaries for the test more compact and increase readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_test_configs(system_messages_list, get_response_func, engine):\n",
    "    message_test_configs = []\n",
    "    for iter_system_message in system_messages_list:\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=iter_system_message[1],\n",
    "                prompt_template=\"{content_html}\",\n",
    "                additional_args={'response_name': iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "        message_test_configs.append(\n",
    "            create_config_dict_func(\n",
    "                get_response_func=get_response_func,\n",
    "                rate_limiter=RateLimiter(50000),\n",
    "                engine=engine,\n",
    "                system_message_template=\"\",\n",
    "                prompt_template=\"{content_html}\" + f\"\"\"\\n\\n\"\"\" + iter_system_message[1],\n",
    "                additional_args={'response_name': \"nosm_\"+iter_system_message[0]}\n",
    "            )\n",
    "        )\n",
    "    return message_test_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configs and run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt configs\n",
    "gpt3_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, \"gpt-3.5-turbo\")\n",
    "gpt4_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_openai, 'gpt-4-turbo-preview')\n",
    "\n",
    "#claude configs\n",
    "haiku_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-haiku-20240307\")\n",
    "opus_prompt_testing_configs = create_message_test_configs(system_messages_list, get_response_anthropic, \"claude-3-opus-20240229\")\n",
    "\n",
    "#run the experiment on all the prompt configs and save to the folder\n",
    "compare_request_configurations(dev_data_df, \n",
    "                               gpt3_prompt_testing_configs + gpt4_prompt_testing_configs + haiku_prompt_testing_configs + opus_prompt_testing_configs,\n",
    "                               folder_path='./data/dev_system_message_variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate system prompt tests\n",
    "\n",
    "We evaluate the system prompts below to see if thre is any significant difference between the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dev_ocr_scores = evaluate_correction_performance('data/dev_raw_ocr', dev_transcripts, wer, cer, 'raw_ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = './data/dev_system_message_variants'\n",
    "\n",
    "performance_eval = evaluate_correction_performance_folders(corrected_folder, dev_transcripts, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt'),:]\n",
    "\n",
    "performance_eval['type'] = performance_eval['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "\n",
    "performance_eval['model'] = performance_eval['type'].str.split('_').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>56.55</td>\n",
       "      <td>74.70</td>\n",
       "      <td>-29.86</td>\n",
       "      <td>43.62</td>\n",
       "      <td>-29.53</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.64</td>\n",
       "      <td>75.47</td>\n",
       "      <td>44.57</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.02</td>\n",
       "      <td>48.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.07</td>\n",
       "      <td>77.36</td>\n",
       "      <td>41.74</td>\n",
       "      <td>55.14</td>\n",
       "      <td>39.58</td>\n",
       "      <td>52.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>68.79</td>\n",
       "      <td>77.39</td>\n",
       "      <td>25.49</td>\n",
       "      <td>55.41</td>\n",
       "      <td>25.91</td>\n",
       "      <td>56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.19</td>\n",
       "      <td>77.36</td>\n",
       "      <td>44.01</td>\n",
       "      <td>56.22</td>\n",
       "      <td>42.49</td>\n",
       "      <td>53.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.25</td>\n",
       "      <td>77.36</td>\n",
       "      <td>41.81</td>\n",
       "      <td>58.38</td>\n",
       "      <td>40.48</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>72.85</td>\n",
       "      <td>76.02</td>\n",
       "      <td>49.35</td>\n",
       "      <td>58.54</td>\n",
       "      <td>47.96</td>\n",
       "      <td>53.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>71.35</td>\n",
       "      <td>75.86</td>\n",
       "      <td>50.45</td>\n",
       "      <td>58.71</td>\n",
       "      <td>49.13</td>\n",
       "      <td>58.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.73</td>\n",
       "      <td>76.02</td>\n",
       "      <td>47.31</td>\n",
       "      <td>59.73</td>\n",
       "      <td>45.54</td>\n",
       "      <td>49.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_claude-3-opus-20240229</th>\n",
       "      <td>70.79</td>\n",
       "      <td>77.36</td>\n",
       "      <td>42.16</td>\n",
       "      <td>60.00</td>\n",
       "      <td>40.97</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_claude-3-opus-20240229</th>\n",
       "      <td>63.66</td>\n",
       "      <td>78.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>63.23</td>\n",
       "      <td>5.51</td>\n",
       "      <td>55.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>75.92</td>\n",
       "      <td>79.25</td>\n",
       "      <td>59.19</td>\n",
       "      <td>64.39</td>\n",
       "      <td>56.97</td>\n",
       "      <td>61.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.73</td>\n",
       "      <td>77.59</td>\n",
       "      <td>56.30</td>\n",
       "      <td>64.86</td>\n",
       "      <td>54.26</td>\n",
       "      <td>58.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.67</td>\n",
       "      <td>80.46</td>\n",
       "      <td>46.82</td>\n",
       "      <td>68.01</td>\n",
       "      <td>45.19</td>\n",
       "      <td>62.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.42</td>\n",
       "      <td>80.46</td>\n",
       "      <td>58.95</td>\n",
       "      <td>68.78</td>\n",
       "      <td>57.84</td>\n",
       "      <td>66.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_claude-3-opus-20240229</th>\n",
       "      <td>73.95</td>\n",
       "      <td>80.46</td>\n",
       "      <td>55.57</td>\n",
       "      <td>69.66</td>\n",
       "      <td>53.61</td>\n",
       "      <td>61.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      WER           CER  \\\n",
       "                                                     mean    50%   mean   \n",
       "type                                                                      \n",
       "nosm_expert_recover_publication_text_prompt_cla...  56.55  74.70 -29.86   \n",
       "nosm_expert_recover_publication_prompt_claude-3...  71.64  75.47  44.57   \n",
       "expert_recover_publication_prompt_claude-3-opus...  71.07  77.36  41.74   \n",
       "full_context_prompt_claude-3-opus-20240229          68.79  77.39  25.49   \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   72.19  77.36  44.01   \n",
       "basic_prompt_claude-3-opus-20240229                 72.25  77.36  41.81   \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   72.85  76.02  49.35   \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  71.35  75.86  50.45   \n",
       "nosm_basic_prompt_claude-3-opus-20240229            70.73  76.02  47.31   \n",
       "expert_recover_publication_text_prompt_claude-3...  70.79  77.36  42.16   \n",
       "expert_recover_prompt_claude-3-opus-20240229        63.66  78.30   4.86   \n",
       "expert_basic_prompt_claude-3-opus-20240229          75.92  79.25  59.19   \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     73.73  77.59  56.30   \n",
       "expert_recover_instructions_prompt_claude-3-opu...  73.67  80.46  46.82   \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     73.42  80.46  58.95   \n",
       "nosm_expert_recover_instructions_prompt_claude-...  73.95  80.46  55.57   \n",
       "\n",
       "                                                          lev_dist         \n",
       "                                                      50%     mean    50%  \n",
       "type                                                                       \n",
       "nosm_expert_recover_publication_text_prompt_cla...  43.62   -29.53  45.00  \n",
       "nosm_expert_recover_publication_prompt_claude-3...  49.56    43.02  48.07  \n",
       "expert_recover_publication_prompt_claude-3-opus...  55.14    39.58  52.66  \n",
       "full_context_prompt_claude-3-opus-20240229          55.41    25.91  56.00  \n",
       "expert_recover_text_prompt_claude-3-opus-20240229   56.22    42.49  53.72  \n",
       "basic_prompt_claude-3-opus-20240229                 58.38    40.48  55.60  \n",
       "nosm_expert_recover_prompt_claude-3-opus-20240229   58.54    47.96  53.88  \n",
       "nosm_expert_recover_text_prompt_claude-3-opus-2...  58.71    49.13  58.31  \n",
       "nosm_basic_prompt_claude-3-opus-20240229            59.73    45.54  49.76  \n",
       "expert_recover_publication_text_prompt_claude-3...  60.00    40.97  55.60  \n",
       "expert_recover_prompt_claude-3-opus-20240229        63.23     5.51  55.60  \n",
       "expert_basic_prompt_claude-3-opus-20240229          64.39    56.97  61.79  \n",
       "nosm_expert_basic_prompt_claude-3-opus-20240229     64.86    54.26  58.99  \n",
       "expert_recover_instructions_prompt_claude-3-opu...  68.01    45.19  62.87  \n",
       "nosm_full_context_prompt_claude-3-opus-20240229     68.78    57.84  66.36  \n",
       "nosm_expert_recover_instructions_prompt_claude-...  69.66    53.61  61.94  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test['type'].str.contains('opus')].groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('CER', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>148.67</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>146.67</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_full_context_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>158.33</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_instructions_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>149.62</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>160.71</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>168.38</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>192.76</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>153.86</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_publication_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>208.90</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_recover_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>158.19</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>163.95</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>154.38</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>153.86</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_text_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>233.00</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_basic_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>307.05</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosm_expert_recover_publication_prompt_gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.11</td>\n",
       "      <td>229.57</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         WER  \\\n",
       "                                                                        mean   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.23   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.23   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.24   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.23   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.26   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.25   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.26   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.25   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.27   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.24   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.24   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.24   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.24   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.35   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.34   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.30   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.15   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.16   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.16   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.16   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.21   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.14   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.18   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.18   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.14   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.16   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.24   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.14   \n",
       "\n",
       "                                                                         CER  \\\n",
       "                                                                        mean   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.13   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.13   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.14   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.13   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.15   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.15   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.15   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.14   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.15   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.14   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.14   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.14   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.14   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.25   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.23   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.19   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                         50%   \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.06   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview  0.06   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.07   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview  0.05   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview  0.05   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.06   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  0.09   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  0.06   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  0.05   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  0.05   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  0.05   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  0.05   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  0.06   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  0.06   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  0.09   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  0.11   \n",
       "\n",
       "                                                                       lev_dist  \\\n",
       "                                                                           mean   \n",
       "type                                               model                          \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview   148.67   \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview   146.67   \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview   158.33   \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview   149.62   \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview   160.71   \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview   168.38   \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview   192.76   \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview   153.86   \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview   208.90   \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview   158.19   \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview   163.95   \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview   154.38   \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview   153.86   \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview   233.00   \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview   307.05   \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview   229.57   \n",
       "\n",
       "                                                                               \n",
       "                                                                          50%  \n",
       "type                                               model                       \n",
       "full_context_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview   72.0  \n",
       "nosm_expert_recover_instructions_prompt_gpt-4-t... gpt-4-turbo-preview   75.0  \n",
       "nosm_full_context_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview   76.0  \n",
       "expert_recover_instructions_prompt_gpt-4-turbo-... gpt-4-turbo-preview   81.0  \n",
       "expert_recover_publication_prompt_gpt-4-turbo-p... gpt-4-turbo-preview   85.0  \n",
       "nosm_expert_recover_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  105.0  \n",
       "expert_recover_prompt_gpt-4-turbo-preview          gpt-4-turbo-preview  110.0  \n",
       "nosm_expert_recover_text_prompt_gpt-4-turbo-pre... gpt-4-turbo-preview  110.0  \n",
       "expert_recover_publication_text_prompt_gpt-4-tu... gpt-4-turbo-preview  114.0  \n",
       "expert_recover_text_prompt_gpt-4-turbo-preview     gpt-4-turbo-preview  114.0  \n",
       "basic_prompt_gpt-4-turbo-preview                   gpt-4-turbo-preview  115.0  \n",
       "expert_basic_prompt_gpt-4-turbo-preview            gpt-4-turbo-preview  115.0  \n",
       "nosm_expert_basic_prompt_gpt-4-turbo-preview       gpt-4-turbo-preview  118.0  \n",
       "nosm_expert_recover_publication_text_prompt_gpt... gpt-4-turbo-preview  121.0  \n",
       "nosm_basic_prompt_gpt-4-turbo-preview              gpt-4-turbo-preview  124.0  \n",
       "nosm_expert_recover_publication_prompt_gpt-4-tu... gpt-4-turbo-preview  129.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval2 = performance_eval.copy()\n",
    "performance_eval2['type'] = performance_eval2['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "performance_eval2['model'] = performance_eval2['type'].str.split('_').str[-1]\n",
    "performance_eval2 = performance_eval2.loc[performance_eval2['model'].str.contains('gpt-4')]\n",
    "performance_eval2.drop(columns = 'File Name').groupby(['type', 'model']).describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions of the prompt test\n",
    "\n",
    "It appears that the placing the prompt after the text instead of using the system prompt gives the best results. However, the prompts did give significantlty different performance.  I think that perhaps using the `full_context_prompt` and the `expert_recover_publication_prompt` with no system message and the prompt after the text may be the best option. This will require twice as much compute as I was planning to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create basic and no message responses\n",
    "\n",
    "Having identified two different prompts and that the prompts appear to work better when places after the text we can now compare the different models\n",
    "\n",
    "\n",
    "The below code creates the basic configuration dictionaries for each model and then fills in the with the two different prompt messages creating a single list of all basic prompt/model configurations. It then calls all the LLM's and saves the results.\n",
    "This works in series so takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the prompt/system message using the best performing from the previous section\n",
    "\n",
    "full_prompt = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. The text is from an english newspaper in the 1800's. The text may be an advert or article and may be missing the beggining or end. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "instruct_prompt = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"You are an expert in post-OCR correction of documents. Using the context available from the text please recover the most likely original text from the corrupted OCR. Do not add any text, commentary, or lead in sentences beyond the recovered text. Do not add a title, or any introductions.\"\"\"\n",
    "\n",
    "boros_basic  = \"{content_html}\"+f\"\"\" \\n \\n \"\"\" +\"Correct the text\"\n",
    "\n",
    "boros_complex  =\"{content_html}\"+f\"\"\" \\n \\n \"\"\" + f\"\"\"Please assist with reviewing and correcting errors in texts produced by automatic transcription (OCR) of historical documents.\n",
    "Your task is to carefully examine the following text and correct any mistakes introduced by the OCR software. \n",
    "Do not write anything else than the corrected text.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_alt_endpoint = {'alt_endpoint':{'base_url':'https://api.groq.com/openai/v1',\n",
    "                     'api_key':os.getenv(\"GROQ_API_KEY\")}}\n",
    "\n",
    "basic_model_configs = pd.DataFrame({\n",
    "    'get_response_func': [get_response_openai, get_response_openai, get_response_anthropic, get_response_anthropic, \n",
    "                          get_response_openai, get_response_openai, get_response_openai], \n",
    "    'engine': ['gpt-3.5-turbo', 'gpt-4-turbo-preview', \"claude-3-haiku-20240307\", \"claude-3-opus-20240229\", \n",
    "               'mixtral-8x7b-32768', 'llama2-70b-4096', 'gemma-7b-it'],\n",
    "    'additional_args': [\n",
    "        {}, {}, {}, {}, \n",
    "        groq_alt_endpoint, \n",
    "        groq_alt_endpoint, \n",
    "        groq_alt_endpoint\n",
    "    ]\n",
    "})\n",
    "\n",
    "base_model_configs= []\n",
    "\n",
    "for index, row in basic_model_configs.iterrows():\n",
    "    #modify the response name for the type\n",
    "    row['additional_args']['response_name'] = 'full_'\n",
    "    base_model_configs.append(\n",
    "\n",
    "        create_config_dict_func(\n",
    "    get_response_func = row['get_response_func'],\n",
    "    rate_limiter = RateLimiter(40000),\n",
    "    engine = row['engine'],\n",
    "    system_message_template = \"\",\n",
    "    prompt_template =  full_prompt,\n",
    "    additional_args=row['additional_args']\n",
    "    )\n",
    "\n",
    "    )\n",
    "\n",
    "nosm_model_configs = []\n",
    "\n",
    "for index, row in basic_model_configs.iterrows():\n",
    "    #modify the response name for the type\n",
    "    row['additional_args']['response_name'] = 'instruct_' \n",
    "    nosm_model_configs.append(\n",
    "\n",
    "        create_config_dict_func(\n",
    "    get_response_func = row['get_response_func'],\n",
    "    rate_limiter = RateLimiter(40000),\n",
    "    engine = row['engine'],\n",
    "    system_message_template = \"\",\n",
    "    prompt_template =  instruct_prompt ,\n",
    "    additional_args=row['additional_args']\n",
    "    )\n",
    "\n",
    "    )\n",
    "\n",
    "boros_list = [create_config_dict_func(\n",
    "    get_response_func = get_response_openai,\n",
    "    rate_limiter = RateLimiter(40000),\n",
    "    engine = 'gpt-4-turbo-preview',\n",
    "    system_message_template = \"\",\n",
    "    prompt_template =  boros_complex ,\n",
    "    additional_args={\"response_name\":\"boros_complex_\"}\n",
    "),\n",
    "\n",
    "create_config_dict_func(\n",
    "    get_response_func = get_response_openai,\n",
    "    rate_limiter = RateLimiter(40000),\n",
    "    engine = 'gpt-4-turbo-preview',\n",
    "    system_message_template = \"\",\n",
    "    prompt_template =  boros_basic ,\n",
    "    additional_args={\"response_name\":\"boros_basic_\"}\n",
    "),\n",
    "\n",
    "create_config_dict_func(\n",
    "    get_response_func = get_response_anthropic,\n",
    "    rate_limiter = RateLimiter(40000),\n",
    "    engine = \"claude-3-opus-20240229\",\n",
    "    system_message_template = \"\",\n",
    "    prompt_template =  boros_basic ,\n",
    "    additional_args={\"response_name\":\"boros_complex_\"}\n",
    ")]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_configs = base_model_configs + nosm_model_configs + boros_list\n",
    "\n",
    "compare_request_configurations(dev_data_df, model_configs, folder_path='./data/dev_corrected_base')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "500*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_folder = './data/dev_corrected_base'\n",
    "\n",
    "performance_eval =  evaluate_correction_performance_folders(corrected_folder, dev_transcripts, wer, cer)\n",
    "\n",
    "performance_eval =  performance_eval.loc[(performance_eval['File Name']!='slug_ar02501_periodical_pc_issue_tec_06121884_page_number_25.txt') &\n",
    "                     (performance_eval['type']!='gpt3_boros_blank_gpt-3.5-turbo'),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the prompts across all models\n",
    "\n",
    "On the smaller models, Full is worse than instruct on the larger models the reverse. Maybe this is related to ability to 'focus' or hold isntructions in memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full__gemma-7b-it</th>\n",
       "      <td>-5.62</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>-178.23</td>\n",
       "      <td>-20.73</td>\n",
       "      <td>-169.37</td>\n",
       "      <td>-19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gemma-7b-it</th>\n",
       "      <td>-5.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-249.75</td>\n",
       "      <td>-20.41</td>\n",
       "      <td>-237.58</td>\n",
       "      <td>-15.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__mixtral-8x7b-32768</th>\n",
       "      <td>30.89</td>\n",
       "      <td>47.79</td>\n",
       "      <td>-116.89</td>\n",
       "      <td>-6.08</td>\n",
       "      <td>-110.08</td>\n",
       "      <td>-6.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mixtral-8x7b-32768</th>\n",
       "      <td>26.93</td>\n",
       "      <td>41.79</td>\n",
       "      <td>-146.28</td>\n",
       "      <td>-4.27</td>\n",
       "      <td>-138.44</td>\n",
       "      <td>-4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__llama2-70b-4096</th>\n",
       "      <td>-3.91</td>\n",
       "      <td>55.40</td>\n",
       "      <td>-290.94</td>\n",
       "      <td>-4.12</td>\n",
       "      <td>-289.14</td>\n",
       "      <td>-2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__llama2-70b-4096</th>\n",
       "      <td>37.29</td>\n",
       "      <td>45.61</td>\n",
       "      <td>-52.95</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-65.63</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-haiku-20240307</th>\n",
       "      <td>52.62</td>\n",
       "      <td>61.15</td>\n",
       "      <td>-24.53</td>\n",
       "      <td>28.05</td>\n",
       "      <td>-20.74</td>\n",
       "      <td>25.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__claude-3-opus-20240229</th>\n",
       "      <td>59.86</td>\n",
       "      <td>70.85</td>\n",
       "      <td>-55.37</td>\n",
       "      <td>36.00</td>\n",
       "      <td>-49.38</td>\n",
       "      <td>33.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-3.5-turbo</th>\n",
       "      <td>54.55</td>\n",
       "      <td>70.75</td>\n",
       "      <td>26.31</td>\n",
       "      <td>39.70</td>\n",
       "      <td>23.73</td>\n",
       "      <td>38.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-haiku-20240307</th>\n",
       "      <td>58.14</td>\n",
       "      <td>69.89</td>\n",
       "      <td>8.32</td>\n",
       "      <td>47.51</td>\n",
       "      <td>9.39</td>\n",
       "      <td>47.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-3.5-turbo</th>\n",
       "      <td>69.54</td>\n",
       "      <td>74.27</td>\n",
       "      <td>51.08</td>\n",
       "      <td>56.52</td>\n",
       "      <td>47.85</td>\n",
       "      <td>50.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_basic__gpt-4-turbo-preview</th>\n",
       "      <td>70.61</td>\n",
       "      <td>75.86</td>\n",
       "      <td>54.88</td>\n",
       "      <td>54.18</td>\n",
       "      <td>52.39</td>\n",
       "      <td>54.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-4-turbo-preview</th>\n",
       "      <td>70.96</td>\n",
       "      <td>75.44</td>\n",
       "      <td>40.36</td>\n",
       "      <td>58.23</td>\n",
       "      <td>38.91</td>\n",
       "      <td>57.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-4-turbo-preview</th>\n",
       "      <td>72.09</td>\n",
       "      <td>79.31</td>\n",
       "      <td>52.75</td>\n",
       "      <td>61.63</td>\n",
       "      <td>50.50</td>\n",
       "      <td>58.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__gpt-4-turbo-preview</th>\n",
       "      <td>71.98</td>\n",
       "      <td>77.19</td>\n",
       "      <td>43.96</td>\n",
       "      <td>61.35</td>\n",
       "      <td>41.64</td>\n",
       "      <td>60.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-opus-20240229</th>\n",
       "      <td>57.05</td>\n",
       "      <td>77.70</td>\n",
       "      <td>23.18</td>\n",
       "      <td>61.30</td>\n",
       "      <td>22.99</td>\n",
       "      <td>61.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__claude-3-opus-20240229</th>\n",
       "      <td>75.32</td>\n",
       "      <td>80.46</td>\n",
       "      <td>60.10</td>\n",
       "      <td>69.33</td>\n",
       "      <td>57.60</td>\n",
       "      <td>63.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         WER            CER        lev_dist  \\\n",
       "                                        mean    50%    mean    50%     mean   \n",
       "type                                                                          \n",
       "full__gemma-7b-it                      -5.62  -2.51 -178.23 -20.73  -169.37   \n",
       "instruct__gemma-7b-it                  -5.04   1.08 -249.75 -20.41  -237.58   \n",
       "instruct__mixtral-8x7b-32768           30.89  47.79 -116.89  -6.08  -110.08   \n",
       "full__mixtral-8x7b-32768               26.93  41.79 -146.28  -4.27  -138.44   \n",
       "full__llama2-70b-4096                  -3.91  55.40 -290.94  -4.12  -289.14   \n",
       "instruct__llama2-70b-4096              37.29  45.61  -52.95   3.00   -65.63   \n",
       "full__claude-3-haiku-20240307          52.62  61.15  -24.53  28.05   -20.74   \n",
       "boros_complex__claude-3-opus-20240229  59.86  70.85  -55.37  36.00   -49.38   \n",
       "full__gpt-3.5-turbo                    54.55  70.75   26.31  39.70    23.73   \n",
       "instruct__claude-3-haiku-20240307      58.14  69.89    8.32  47.51     9.39   \n",
       "instruct__gpt-3.5-turbo                69.54  74.27   51.08  56.52    47.85   \n",
       "boros_basic__gpt-4-turbo-preview       70.61  75.86   54.88  54.18    52.39   \n",
       "instruct__gpt-4-turbo-preview          70.96  75.44   40.36  58.23    38.91   \n",
       "full__gpt-4-turbo-preview              72.09  79.31   52.75  61.63    50.50   \n",
       "boros_complex__gpt-4-turbo-preview     71.98  77.19   43.96  61.35    41.64   \n",
       "instruct__claude-3-opus-20240229       57.05  77.70   23.18  61.30    22.99   \n",
       "full__claude-3-opus-20240229           75.32  80.46   60.10  69.33    57.60   \n",
       "\n",
       "                                              \n",
       "                                         50%  \n",
       "type                                          \n",
       "full__gemma-7b-it                     -19.76  \n",
       "instruct__gemma-7b-it                 -15.52  \n",
       "instruct__mixtral-8x7b-32768           -6.95  \n",
       "full__mixtral-8x7b-32768               -4.19  \n",
       "full__llama2-70b-4096                  -2.54  \n",
       "instruct__llama2-70b-4096               2.54  \n",
       "full__claude-3-haiku-20240307          25.43  \n",
       "boros_complex__claude-3-opus-20240229  33.77  \n",
       "full__gpt-3.5-turbo                    38.77  \n",
       "instruct__claude-3-haiku-20240307      47.09  \n",
       "instruct__gpt-3.5-turbo                50.91  \n",
       "boros_basic__gpt-4-turbo-preview       54.28  \n",
       "instruct__gpt-4-turbo-preview          57.45  \n",
       "full__gpt-4-turbo-preview              58.64  \n",
       "boros_complex__gpt-4-turbo-preview     60.45  \n",
       "instruct__claude-3-opus-20240229       61.23  \n",
       "full__claude-3-opus-20240229           63.69  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_metric_error_reduction(performance_eval, raw_dev_ocr_scores)\n",
    "\n",
    "test.groupby('type').describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">WER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lev_dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full__claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>150.52</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_basic__gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>170.90</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>164.62</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>186.76</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__gpt-4-turbo-preview</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>183.90</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>380.76</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "      <td>323.05</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gpt-3.5-turbo</th>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>189.38</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boros_complex__claude-3-opus-20240229</th>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>233.48</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__haiku</th>\n",
       "      <th>haiku</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>329.33</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gpt-3.5-turbo</th>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.08</td>\n",
       "      <td>305.38</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__llama2-70b-4096</th>\n",
       "      <th>llama2-70b-4096</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.22</td>\n",
       "      <td>639.43</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__mixtral-8x7b-32768</th>\n",
       "      <th>mixtral-8x7b-32768</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>708.19</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__llama2-70b-4096</th>\n",
       "      <th>llama2-70b-4096</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1153.19</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__mixtral-8x7b-32768</th>\n",
       "      <th>mixtral-8x7b-32768</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>724.19</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full__gemma-7b-it</th>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.49</td>\n",
       "      <td>799.10</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instruct__gemma-7b-it</th>\n",
       "      <th>gemma-7b-it</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>927.67</td>\n",
       "      <td>474.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               WER        \\\n",
       "                                                              mean   50%   \n",
       "type                                  model                                \n",
       "full__claude-3-opus-20240229          claude-3-opus-20240229  0.23  0.11   \n",
       "boros_basic__gpt-4-turbo-preview      gpt-4-turbo-preview     0.26  0.18   \n",
       "full__gpt-4-turbo-preview             gpt-4-turbo-preview     0.26  0.16   \n",
       "instruct__gpt-4-turbo-preview         gpt-4-turbo-preview     0.25  0.19   \n",
       "boros_complex__gpt-4-turbo-preview    gpt-4-turbo-preview     0.24  0.17   \n",
       "instruct__claude-3-opus-20240229      claude-3-opus-20240229  0.33  0.12   \n",
       "instruct__haiku                       haiku                   0.32  0.26   \n",
       "instruct__gpt-3.5-turbo               gpt-3.5-turbo           0.29  0.16   \n",
       "boros_complex__claude-3-opus-20240229 claude-3-opus-20240229  0.32  0.30   \n",
       "full__haiku                           haiku                   0.35  0.32   \n",
       "full__gpt-3.5-turbo                   gpt-3.5-turbo           0.36  0.32   \n",
       "instruct__llama2-70b-4096             llama2-70b-4096         0.53  0.51   \n",
       "instruct__mixtral-8x7b-32768          mixtral-8x7b-32768      0.52  0.45   \n",
       "full__llama2-70b-4096                 llama2-70b-4096         0.78  0.41   \n",
       "full__mixtral-8x7b-32768              mixtral-8x7b-32768      0.54  0.56   \n",
       "full__gemma-7b-it                     gemma-7b-it             0.83  0.91   \n",
       "instruct__gemma-7b-it                 gemma-7b-it             0.80  0.86   \n",
       "\n",
       "                                                               CER        \\\n",
       "                                                              mean   50%   \n",
       "type                                  model                                \n",
       "full__claude-3-opus-20240229          claude-3-opus-20240229  0.13  0.05   \n",
       "boros_basic__gpt-4-turbo-preview      gpt-4-turbo-preview     0.15  0.06   \n",
       "full__gpt-4-turbo-preview             gpt-4-turbo-preview     0.15  0.06   \n",
       "instruct__gpt-4-turbo-preview         gpt-4-turbo-preview     0.15  0.06   \n",
       "boros_complex__gpt-4-turbo-preview    gpt-4-turbo-preview     0.14  0.07   \n",
       "instruct__claude-3-opus-20240229      claude-3-opus-20240229  0.22  0.06   \n",
       "instruct__haiku                       haiku                   0.21  0.13   \n",
       "instruct__gpt-3.5-turbo               gpt-3.5-turbo           0.17  0.06   \n",
       "boros_complex__claude-3-opus-20240229 claude-3-opus-20240229  0.23  0.20   \n",
       "full__haiku                           haiku                   0.24  0.16   \n",
       "full__gpt-3.5-turbo                   gpt-3.5-turbo           0.22  0.08   \n",
       "instruct__llama2-70b-4096             llama2-70b-4096         0.33  0.22   \n",
       "instruct__mixtral-8x7b-32768          mixtral-8x7b-32768      0.39  0.37   \n",
       "full__llama2-70b-4096                 llama2-70b-4096         0.55  0.29   \n",
       "full__mixtral-8x7b-32768              mixtral-8x7b-32768      0.41  0.44   \n",
       "full__gemma-7b-it                     gemma-7b-it             0.46  0.49   \n",
       "instruct__gemma-7b-it                 gemma-7b-it             0.52  0.57   \n",
       "\n",
       "                                                             lev_dist         \n",
       "                                                                 mean    50%  \n",
       "type                                  model                                   \n",
       "full__claude-3-opus-20240229          claude-3-opus-20240229   150.52   87.0  \n",
       "boros_basic__gpt-4-turbo-preview      gpt-4-turbo-preview      170.90   91.0  \n",
       "full__gpt-4-turbo-preview             gpt-4-turbo-preview      164.62   91.0  \n",
       "instruct__gpt-4-turbo-preview         gpt-4-turbo-preview      186.76   91.0  \n",
       "boros_complex__gpt-4-turbo-preview    gpt-4-turbo-preview      183.90   98.0  \n",
       "instruct__claude-3-opus-20240229      claude-3-opus-20240229   380.76  111.0  \n",
       "instruct__haiku                       haiku                    323.05  118.0  \n",
       "instruct__gpt-3.5-turbo               gpt-3.5-turbo            189.38  119.0  \n",
       "boros_complex__claude-3-opus-20240229 claude-3-opus-20240229   233.48  154.0  \n",
       "full__haiku                           haiku                    329.33  156.0  \n",
       "full__gpt-3.5-turbo                   gpt-3.5-turbo            305.38  164.0  \n",
       "instruct__llama2-70b-4096             llama2-70b-4096          639.43  202.0  \n",
       "instruct__mixtral-8x7b-32768          mixtral-8x7b-32768       708.19  264.0  \n",
       "full__llama2-70b-4096                 llama2-70b-4096         1153.19  274.0  \n",
       "full__mixtral-8x7b-32768              mixtral-8x7b-32768       724.19  281.0  \n",
       "full__gemma-7b-it                     gemma-7b-it              799.10  441.0  \n",
       "instruct__gemma-7b-it                 gemma-7b-it              927.67  474.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_eval2 = performance_eval.copy()\n",
    "performance_eval2['type'] = performance_eval2['type'].str.replace(\"claude-3-haiku-20240307\", \"haiku\").replace(\"gpt-3.5-turbo\", \"gpt-3.5\")\n",
    "performance_eval2['model'] = performance_eval2['type'].str.split('_').str[-1]\n",
    "\n",
    "#The below line allows you to look at an individual model\n",
    "#performance_eval2 = performance_eval2.loc[performance_eval2['model'].str.contains('gpt-4')]\n",
    "\n",
    "performance_eval2.drop(columns = 'File Name').groupby(['type', 'model']).describe().filter(regex = '50|mean').round(2).sort_values(('lev_dist', '50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Llama 2 70B':'llama2-70b-4096\t',\n",
    " 'Gemma 7B':'gemma-7b-it':\n",
    " 'Opus':'claude-3-opus-20240229',\n",
    " 'Haiku':'haiku',\n",
    " 'GPT-4':'gpt-4-turbo-preview',\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Llama 2 70B</th>\n",
       "      <th>Gemma 7B</th>\n",
       "      <th>Opus</th>\n",
       "      <th>Haiku</th>\n",
       "      <th>GPT-4</th>\n",
       "      <th>GPT3.5</th>\n",
       "      <th>Mixtral 8x7B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMLU</td>\n",
       "      <td>69.9</td>\n",
       "      <td>64.6</td>\n",
       "      <td>86.8</td>\n",
       "      <td>75.2</td>\n",
       "      <td>86.4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>87.1</td>\n",
       "      <td>82.2</td>\n",
       "      <td>95.4</td>\n",
       "      <td>85.9</td>\n",
       "      <td>93.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>86.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARC-C</td>\n",
       "      <td>85.1</td>\n",
       "      <td>61.9</td>\n",
       "      <td>96.6</td>\n",
       "      <td>89.2</td>\n",
       "      <td>96.3</td>\n",
       "      <td>85.2</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WinoGrande</td>\n",
       "      <td>83.2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>74.2</td>\n",
       "      <td>87.5</td>\n",
       "      <td>81.6</td>\n",
       "      <td>81.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>49.8</td>\n",
       "      <td>44.4</td>\n",
       "      <td>86.4</td>\n",
       "      <td>80.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.2</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DROP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.1</td>\n",
       "      <td>78.9</td>\n",
       "      <td>80.9</td>\n",
       "      <td>64.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Llama 2 70B  Gemma 7B  Opus  Haiku  GPT-4  GPT3.5  Mixtral 8x7B\n",
       "0        MMLU         69.9      64.6  86.8   75.2   86.4    70.0          70.6\n",
       "1   HellaSwag         87.1      82.2  95.4   85.9   93.3    85.5          86.7\n",
       "2       ARC-C         85.1      61.9  96.6   89.2   96.3    85.2          85.8\n",
       "3  WinoGrande         83.2      79.0  88.5   74.2   87.5    81.6          81.2\n",
       "4        MBPP         49.8      44.4  86.4   80.4    NaN    52.2          60.7\n",
       "5        DROP          NaN       NaN  83.1   78.9   80.9    64.1           NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/benchmarks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
